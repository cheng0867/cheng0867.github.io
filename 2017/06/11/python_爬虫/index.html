<!doctype html>




<html class="theme-next pisces" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="爬虫根据使用场景，分为两种：

通用爬虫：是搜索引擎抓取系统的重要组成部分
聚焦爬虫：实施网页抓取，并对内容进行处理筛选">
<meta property="og:type" content="article">
<meta property="og:title" content="python网络爬虫">
<meta property="og:url" content="http://www.oneskk.com/2017/06/11/python_爬虫/index.html">
<meta property="og:site_name" content="慧海仁心">
<meta property="og:description" content="爬虫根据使用场景，分为两种：

通用爬虫：是搜索引擎抓取系统的重要组成部分
聚焦爬虫：实施网页抓取，并对内容进行处理筛选">
<meta property="og:updated_time" content="2017-06-14T07:18:31.486Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python网络爬虫">
<meta name="twitter:description" content="爬虫根据使用场景，分为两种：

通用爬虫：是搜索引擎抓取系统的重要组成部分
聚焦爬虫：实施网页抓取，并对内容进行处理筛选">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.oneskk.com/2017/06/11/python_爬虫/"/>





  <title> python网络爬虫 | 慧海仁心 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  














  
  
    
  

  <div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">慧海仁心</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.oneskk.com/2017/06/11/python_爬虫/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="金成">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="慧海仁心">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                python网络爬虫
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-11T10:37:23+08:00">
                2017-06-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/网络爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">网络爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <div class="note success"><p>爬虫根据使用场景，分为两种：</p>
<ol>
<li><strong>通用爬虫</strong>：是搜索引擎抓取系统的重要组成部分</li>
<li><strong>聚焦爬虫</strong>：实施网页抓取，并对内容进行处理筛选</li>
</ol>
</div>
<a id="more"></a>
<blockquote>
<p><strong>爬虫所需具备技能</strong></p>
<ol>
<li><strong>基础知识</strong>：Python基础语法</li>
<li><strong>数据抓取</strong>：对<code>HTML</code>页面的内容抓取</li>
<li><strong>数据提取</strong>：对<code>HTML</code>页面的数据提取</li>
<li><strong>第三方框架</strong>：<code>Scrapy</code>框架以及<code>Scrapy-redis</code>分布式策略</li>
</ol>
</blockquote>
<hr>
<h1 id="爬虫原理与数据抓取"><a href="#爬虫原理与数据抓取" class="headerlink" title="爬虫原理与数据抓取"></a>爬虫原理与数据抓取</h1><h2 id="通用爬虫和聚焦爬虫"><a href="#通用爬虫和聚焦爬虫" class="headerlink" title="通用爬虫和聚焦爬虫"></a>通用爬虫和聚焦爬虫</h2><h3 id="通用爬虫"><a href="#通用爬虫" class="headerlink" title="通用爬虫"></a>通用爬虫</h3><p>从互联网上搜索网页、采集信息，为搜索引擎<strong>建立索引</strong>。从而提供搜索支持</p>
<h4 id="第一步：抓取网页"><a href="#第一步：抓取网页" class="headerlink" title="第一步：抓取网页"></a>第一步：抓取网页</h4><p>搜索引擎网络爬虫工作流程：</p>
<ol>
<li>选取部分种子URL，并添加到<strong>待抓取URL队列</strong></li>
<li>取出待抓取URL，解析DNS得到主机的IP，将URL对应的网页下载下来，存储进已下载的网页库中（百度快照），并将这些URL添加进<strong>已抓取URL队列</strong></li>
<li>分析已抓取URL队列中的URL，分析其中的其它URL（外链），并将URL放进<strong>待抓取URL队列</strong>，从而进行下一个循环</li>
</ol>
<p>搜索引擎（如百度）怎样获取一个新网站的URL：</p>
<ol>
<li>向搜索引擎<strong>主动提交</strong>新网站：（百度<a href="http://zhanzhang.baidu.com/linksubmit/url）" target="_blank" rel="external">http://zhanzhang.baidu.com/linksubmit/url）</a></li>
<li>在其它网站添加新网站作为<strong>外链</strong></li>
<li>使用与搜索引擎合作的DNS解析服务商的域名，如DNSPod<blockquote>
<p>Robots协议（爬虫协议）：告知搜索引擎哪些页面可以抓取</p>
</blockquote>
</li>
</ol>
<ul>
<li>淘宝：<a href="https://www.taobao.com/robots.txt" target="_blank" rel="external">https://www.taobao.com/robots.txt</a></li>
<li>腾讯：<a href="http://www.qq.com/robots.txt" target="_blank" rel="external">http://www.qq.com/robots.txt</a></li>
</ul>
<h4 id="第二步：数据存储"><a href="#第二步：数据存储" class="headerlink" title="第二步：数据存储"></a>第二步：数据存储</h4><ol>
<li>搜索引擎将爬虫爬取到的网页，存储到<strong>原始页面数据库</strong>，其页面数据与用户访问时的HTML完全一样</li>
<li>搜索引擎在抓取页面时，做了一定的<strong>重复内容检测</strong>，一旦发现访问权重较低的网站有大量抄袭、采集、复制的内容，很可能不再爬取</li>
</ol>
<h4 id="第三步：预处理"><a href="#第三步：预处理" class="headerlink" title="第三步：预处理"></a>第三步：预处理</h4><p>搜索引擎将爬取的页面，进行各种<strong>预处理</strong></p>
<ul>
<li>提取文字</li>
<li>中文分词</li>
<li>消除噪音（如版权声明文字，导航条，广告…）</li>
<li>索引处理</li>
<li>链接关系计算</li>
<li>特殊文件处理</li>
</ul>
<blockquote>
<p>搜索引擎可以抓取和索引的<strong>以文字为主</strong>，还包括word、ppt、txt等文件，但无法处理图片、视频、脚本、程序</p>
</blockquote>
<h4 id="第四步：提供检索服务，网站排名"><a href="#第四步：提供检索服务，网站排名" class="headerlink" title="第四步：提供检索服务，网站排名"></a>第四步：提供检索服务，网站排名</h4><p>搜索引擎对信息进行阻止和处理后，为用户提供<strong>关键字</strong>检索服务</p>
<ul>
<li><strong>访问量</strong>：根据页面的<code>PageRank</code>值（链接的访问量排名）来进行网站排名</li>
<li><strong>竞价排名</strong>：使用<code>Money</code>购买搜索引擎网站排名</li>
</ul>
<blockquote>
<p>通用搜索引擎的局限性：</p>
<ol>
<li>90%网页中的内容对用户是毋庸的</li>
<li>不同用户检索目的不同，搜索引擎无法针对某个用户提供搜索结果</li>
<li>对图片、数据库、音频、视频等数据无能为力</li>
<li>大多根据关键字的检索，难以支持语义查询，无法准确理解用户的具体需求</li>
</ol>
</blockquote>
<p>所以<strong>聚焦爬虫</strong>相对通用爬虫，更加准确！</p>
<hr>
<h2 id="HTTP和HTTPS"><a href="#HTTP和HTTPS" class="headerlink" title="HTTP和HTTPS"></a>HTTP和HTTPS</h2><ul>
<li><code>HTTP协议</code>（端口：80）：一种发布和接收HTML页面的方法</li>
<li><code>HTTPS</code>（端口：443）：HTTP的安全版，在HTTP中加入了SSL层</li>
<li><code>SSL</code>：主要用于Web的安全传输协议，在传输层对网络链接进行加密，为在internet上数据传输的安全提供保障</li>
</ul>
<h3 id="HTTP工作原理"><a href="#HTTP工作原理" class="headerlink" title="HTTP工作原理"></a>HTTP工作原理</h3><p>网络爬虫<strong>抓取过程</strong>可理解为<code>模拟浏览器操作的过程</code></p>
<p>浏览器的主要功能是<strong>向服务器发出请求</strong><br>在浏览器窗口中<strong>展示网络资源</strong><br><code>HTTP</code>是一套计算机<strong>通过网络进行通信的规则</strong></p>
<p>HTTP通信由两部分组成：<strong>客户端请求消息</strong> 与 <strong>服务器响应消息</strong></p>
<h4 id="浏览器发送HTTP请求的过程"><a href="#浏览器发送HTTP请求的过程" class="headerlink" title="浏览器发送HTTP请求的过程"></a>浏览器发送HTTP请求的过程</h4><ol>
<li>当用户在浏览器<strong>输入URL地址</strong>并回车时，浏览器向HTTP服务器发送HTTP请求。请求方式一般分为<code>GET</code>和<code>POST</code>方式</li>
<li>服务器把Resopnse文件对象发送回给浏览器</li>
<li>浏览器分析HTML时，发现其中引用很多其它类型的文件，如image、css、js，浏览器会自动再次发送Request取获取图片，CSS文件，或者JS文件</li>
<li>当所有文件都下载成功后，网页会根据HTML语法结构，完整的显示出来</li>
</ol>
<h4 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h4><blockquote>
<p><strong>统一资源定位符</strong>：用于完整地描述Internet上网页和其他资源的地址的一种标识方法</p>
</blockquote>
<p>基本格式：<code>scheme://host[:port]/path/.../[?query-string][#anchor]</code></p>
<ul>
<li>scheme：协议（如：http、https、ftp）</li>
<li>host：服务器的IP地址或域名</li>
<li>port：服务器的端口（默认端口为80）</li>
<li>path：访问资源的路径</li>
<li>query-string：参数，发送给http服务器的数据</li>
<li>anchor：锚（跳转到网页的指定锚点位置）</li>
</ul>
<h4 id="客户端HTTP请求"><a href="#客户端HTTP请求" class="headerlink" title="客户端HTTP请求"></a>客户端HTTP请求</h4><p>URL只是<strong>标识资源的位置</strong><br>HTTP用来<strong>提交和获取资源</strong></p>
<p><strong>HTTP请求信息格式</strong>：<br><code>请求行</code>、<code>请求头</code>、<code>空行</code>、<code>请求数据</code></p>
<p><strong>HTTP请求信息示例</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">GET https://www.baidu.com/ HTTP/1.1</div><div class="line">Host: www.baidu.com</div><div class="line">Connection: keep-alive</div><div class="line">Upgrade-Insecure-Requests: 1</div><div class="line">User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36</div><div class="line">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</div><div class="line">Referer: http://www.baidu.com/</div><div class="line">Accept-Encoding: gzip, deflate, sdch, br</div><div class="line">Accept-Language: zh-CN,zh;q=0.8,en;q=0.6</div><div class="line">Cookie: BAIDUID=04E4001F34EA74AD4601512DD3C41A7B:FG=1; BIDUPSID=04E4001F34EA74AD4601512DD3C41A7B; PSTM=1470329258; MCITY=-343%3A340%3A; H_PS_PSSID=1447_18240_21105_21386_21454_21409_21554; BD_UPN=12314753; sug=3; sugstore=0; ORIGIN=0; bdime=0; H_PS_645EC=7e2ad3QHl181NSPbFbd7PRUCE1LlufzxrcFmwYin0E6b%2BW8bbTMKHZbDP0g; BDSVRTM=0</div></pre></td></tr></table></figure></p>
<h4 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h4><p>常用方法：</p>
<ul>
<li><code>GET</code>：请求指定的页面信息，并返回<strong>实体主体</strong></li>
<li><code>POST</code>：<strong>提交处理请求</strong>，数据包含在请求体中，可建立新资源或修改已有资源</li>
</ul>
<p>一般方法：</p>
<ul>
<li><code>HEAD</code>：类似get请求，响应中没有具体内容，只有<strong>报头信息</strong></li>
<li><code>PUT</code>：从客服端向服务器传送的数据<strong>取代</strong>指定的文档内容</li>
<li><code>DELETE</code>：请求服务器<strong>删除</strong>指定的页面</li>
<li><code>CONNECT</code>：将链接改为管道方式的<strong>代理服务器</strong></li>
<li><code>OPTIONS</code>：允许客户端查看服务器的<strong>性能</strong></li>
<li><code>TRACE</code>：回显服务器收到的请求，主要用于<strong>测试或诊断</strong></li>
</ul>
<h4 id="常用的请求报头"><a href="#常用的请求报头" class="headerlink" title="常用的请求报头"></a>常用的请求报头</h4><ol>
<li><code>Host</code>：主机和端口号</li>
<li><code>Connection</code>：链接类型<ul>
<li><code>Connection:keep-alive</code>：保持连接</li>
<li><code>Connection:close</code>：关闭 </li>
</ul>
</li>
<li><code>Upgrade-Insecure-Requests</code>：升级为HTTPS请求</li>
<li><code>User-Agent</code>：浏览器名称（访问客户端名称）</li>
<li><code>Accept</code>：传输文件类型（MIME文件类型）<ul>
<li><code>Accept</code>:*/* ：表示什么都可以接收</li>
<li><code>Accept</code>:image/gif：表明客户端希望接受GIF图像格式的资源</li>
<li><code>Accept</code>:text/html：表明客户端希望接受html文本</li>
<li><code>Accept</code>：text/html,application/xhtml+xml;q=0.9,image/*;q=0.8`：表示浏览器支持的MIME类型分别是html、xhtml和xml、和所有图像格式资源<ul>
<li>q是权重系数，默认为1，0则为不接受该类型</li>
</ul>
</li>
</ul>
</li>
<li><code>Referer</code>：页面跳转处</li>
<li><code>Accept-Encoding</code>：文件编/解码格式</li>
<li><code>Accept-Language</code>：语言种类</li>
<li><code>Accept-Charset</code>：字符编码</li>
<li><code>Cookie</code>：在浏览器中存储的小型数据体</li>
<li><code>Content-Type</code>：POST数据类型</li>
</ol>
<h4 id="服务端HTTP响应"><a href="#服务端HTTP响应" class="headerlink" title="服务端HTTP响应"></a>服务端HTTP响应</h4><p><strong>响应信息示例</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">HTTP/1.1 200 OK</div><div class="line">Server: Tengine</div><div class="line">Connection: keep-alive</div><div class="line">Date: Wed, 30 Nov 2016 07:58:21 GMT</div><div class="line">Cache-Control: no-cache</div><div class="line">Content-Type: text/html;charset=UTF-8</div><div class="line">Keep-Alive: timeout=20</div><div class="line">Vary: Accept-Encoding</div><div class="line">Pragma: no-cache</div><div class="line">X-NWS-LOG-UUID: bd27210a-24e5-4740-8f6c-25dbafa9c395</div><div class="line">Content-Length: 180945</div></pre></td></tr></table></figure></p>
<h3 id="Cookie和Session"><a href="#Cookie和Session" class="headerlink" title="Cookie和Session"></a>Cookie和Session</h3><p><code>cookie</code>：在 客户端 记录信息确定用户的身份<br><code>session</code>：在 服务器 记录信息确定用户的身份</p>
<h2 id="urllib2库的基本使用"><a href="#urllib2库的基本使用" class="headerlink" title="urllib2库的基本使用"></a>urllib2库的基本使用</h2><blockquote>
<p>在python2.7中自带urllib2模块，无需下载，直接导入即可<br>在python3中，urllib2被改为<code>urllib.request</code><br>urllib2官方文档：<a href="https://docs.python.org/2/library/urllib2.html" target="_blank" rel="external">https://docs.python.org/2/library/urllib2.html</a></p>
</blockquote>
<h3 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen"></a>urlopen</h3><blockquote>
<p>urllib2封装的urlopen对象</p>
</blockquote>
<p><strong>示例</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>)</div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure></p>
<h3 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h3><blockquote>
<p>urlopen()的参数是一个<strong>url地址</strong><br>但是如果需要复杂的操作，就必须创建一个Request实例作为urlopen的参数，而需要访问的url地址作为Request实例的参数</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">request = urllib2.Request(<span class="string">'http://www.baidu.com'</span>)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure>
<p><strong>Request实例</strong>，除了必要的url参数，还可设置另外两个参数</p>
<ol>
<li>data(默认空)：随url提交的数据(如post的数据)，同时HTTP请求将从GET方式改为POST方式</li>
<li>headers(默认空)：字典格式，包含需要发送的HTTP报头的键值对</li>
</ol>
<h3 id="User-Agent"><a href="#User-Agent" class="headerlink" title="User-Agent"></a>User-Agent</h3><p>urllib2默认的<code>User-Agent</code>头为：Python-urllib/x.y(x和y是Python主版本和次版本号)<br>需要<em>*伪装真实浏览器信息(User-Agent)</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">url = <span class="string">'http://www.baidu.com'</span></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'</span>&#125;</div><div class="line">request = urllib2.Request(url, headers = headers)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure></p>
<h3 id="添加更多的Header信息"><a href="#添加更多的Header信息" class="headerlink" title="添加更多的Header信息"></a>添加更多的Header信息</h3><blockquote>
<p>通过<code>Request.add_header()</code>添加/修改一个特定的header<br>通过<code>Request.get_header()</code>查看已有的header</p>
</blockquote>
<p><strong>添加一个特定的header</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">url = <span class="string">'http://www.baidu.com'</span></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'</span>&#125;</div><div class="line">request = urllib2.Request(url, headers = headers)</div><div class="line"><span class="comment"># 使用Request.add_header()添加/修改header</span></div><div class="line">request.add_header(<span class="string">'Connection'</span>,<span class="string">'keep-alive'</span>)</div><div class="line"><span class="comment"># 使用Request.get_header()获取header</span></div><div class="line"><span class="comment"># request.get_header(header_name='Connection')</span></div><div class="line"></div><div class="line">response = urllib2.urlopen(request)</div><div class="line"><span class="keyword">print</span> response.code <span class="comment"># 可以查看响应状态码</span></div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure></p>
<p><strong>随机添加/修改User-Agent</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">url = <span class="string">'http://www.baidu.com'</span></div><div class="line">ua_list = [</div><div class="line">    <span class="string">"Mozilla/5.0 (Windows NT 6.1; ) Apple.... "</span>,</div><div class="line">    <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0)... "</span>,</div><div class="line">    <span class="string">"Mozilla/5.0 (Macintosh; U; PPC Mac OS X.... "</span>,</div><div class="line">    <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS... "</span></div><div class="line">]</div><div class="line">user_agent = random.choice(ua_list)</div><div class="line">request = urllib2.Request(url)</div><div class="line">request.add_header(<span class="string">'User-Agent'</span>,user_agent)</div><div class="line"><span class="keyword">print</span> request.get_header(<span class="string">'User-agent'</span>)  <span class="comment"># get_header()方法，参数第一个字母大写，其余小写</span></div><div class="line">response = urllib2.urlopen(request)</div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure></p>
<h2 id="urllib2：GET和POST方法"><a href="#urllib2：GET和POST方法" class="headerlink" title="urllib2：GET和POST方法"></a>urllib2：<code>GET</code>和<code>POST</code>方法</h2><blockquote>
<p>urllib2默认只支持HTTP/HTTPS的<code>GET</code>和<code>POST</code>方法</p>
</blockquote>
<h3 id="URL编码转码：urllib的urlencode"><a href="#URL编码转码：urllib的urlencode" class="headerlink" title="URL编码转码：urllib的urlencode()"></a>URL编码转码：urllib的urlencode()</h3><p>urllib和urllib2都是接受URL请求的相关模块，但是功能不同：</p>
<ul>
<li>urllib模块仅可以接受URL，不能创建 <strong>设置了headers的Request类实例</strong>，urllib2有</li>
<li>urllib提供<code>urlencode</code>方法来GET查询字符串，urllib2没有</li>
<li>编码使用urllib的<code>urlencode()</code>函数，将<code>key:value</code>转换成<code>&quot;key=value&quot;</code>，解码使用urllib的<code>unquote()</code>函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line">word = &#123;<span class="string">'wd'</span>:<span class="string">'哈哈'</span>&#125;</div><div class="line">urllib.urlencode(word)</div></pre></td></tr></table></figure>
<blockquote>
<p>一般HTTP请求提交数据，需要编码成<strong>URL编码格式</strong>，然后作为URL的一部分，或者作为参数传到<strong>Request对象</strong>中</p>
</blockquote>
<h3 id="Get方式"><a href="#Get方式" class="headerlink" title="Get方式"></a>Get方式</h3><blockquote>
<p>GET请求一般用于向服务器<strong>获取数据</strong></p>
</blockquote>
<p>如使用百度发送查询请求<code>https://www.baidu.com/s?wd=%E5%93%88%E5%93%88</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line">imoprt urllib2</div><div class="line"></div><div class="line">url = <span class="string">'http://www.baidu.com/s?'</span></div><div class="line">word = &#123;<span class="string">'wd'</span>:<span class="string">'哈哈'</span>&#125;</div><div class="line">word = urllib.urlencode(word)</div><div class="line">fullurl = url + word</div><div class="line"></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'</span>&#125;</div><div class="line">request = urllib2.Request(fullurl,headers = headers)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line">html = response.read()</div><div class="line"><span class="keyword">print</span> html</div></pre></td></tr></table></figure></p>
<h3 id="百度贴吧小爬虫"><a href="#百度贴吧小爬虫" class="headerlink" title="百度贴吧小爬虫"></a>百度贴吧小爬虫</h3><p>参考URL：<code>http://tieba.baidu.com/f?kw=lol&amp;pn=50</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(url, filename)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'正在加载：'</span>,filename</div><div class="line">    headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'</span>&#125;</div><div class="line">    request = urllib2.Request(url, headers = headers)</div><div class="line">    response = urllib2.urlopen(request)</div><div class="line">    html = response.read()</div><div class="line">    <span class="keyword">return</span> html</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">writePage</span><span class="params">(html, filename)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'正在写入：'</span>,filename</div><div class="line">    <span class="keyword">with</span> open(filename,<span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">        f.write(html)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tiebaSpider</span><span class="params">(url, begin, end)</span>:</span></div><div class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> range(begin, end + <span class="number">1</span>):</div><div class="line">        pn = (page - <span class="number">1</span>) * <span class="number">50</span></div><div class="line">        fullurl = url + str(pn)</div><div class="line">        filename = <span class="string">'No.'</span> + str(page) + <span class="string">'.html'</span></div><div class="line">        html = loadPage(fullurl, filename)</div><div class="line">        writePage(html,filename)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    kw = raw_input(<span class="string">'请输入贴吧名称：'</span>)</div><div class="line">    begin = int(raw_input(<span class="string">'起始页：'</span>))</div><div class="line">    end = int(raw_input(<span class="string">'结束页：'</span>)</div><div class="line">    url = <span class="string">'http://tieba.baidu.com/f?'</span></div><div class="line">    key = urllib.urlencode(&#123;<span class="string">'kw'</span>:kw&#125;)</div><div class="line">    url = url + key</div><div class="line">    tiebaSpider(url, begin, end)</div></pre></td></tr></table></figure></p>
<h3 id="获取AJAX加载的内容"><a href="#获取AJAX加载的内容" class="headerlink" title="获取AJAX加载的内容"></a>获取AJAX加载的内容</h3><p>使用AJAX请求加载的网页，这种数据<strong>无法直接对URL进行获取</strong><br>但是，AJAX请求一般返回给网页<strong>JSON文件</strong>，只要对AJAX请求地址进行<strong>POST</strong>或<strong>GET</strong>，就可以返回JSON数据了<br>豆瓣电影：<code>https://movie.douban.com/j/chart/top_list?type=17&amp;interval_id=100&quot;%&quot;3A90&amp;action=&amp;</code><br><strong>示例1</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">url = <span class="string">'https://movie.douban.com/j/chart/top_list?type=17&amp;interval_id=100:90&amp;action=&amp;'</span></div><div class="line">formdata = &#123;</div><div class="line">    <span class="string">'start'</span>:<span class="string">'0'</span>,</div><div class="line">    <span class="string">'limit'</span>:<span class="string">'10'</span></div><div class="line">&#125;</div><div class="line">data = urllib.urlencode(formdata)</div><div class="line">request = urllib2.Request(url + data, headers = headers)</div><div class="line">response = urllib2.urlencode(request)</div><div class="line"><span class="keyword">print</span> response.read()</div></pre></td></tr></table></figure></p>
<h3 id="POST方式"><a href="#POST方式" class="headerlink" title="POST方式"></a>POST方式</h3><p>有道词典URL：<code>http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line">txt = raw_input(<span class="string">'请输入查询内容：'</span>)</div><div class="line">url = <span class="string">'http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null'</span></div><div class="line">formdata = &#123;</div><div class="line">    <span class="string">"type"</span>:<span class="string">"AUTO"</span>,</div><div class="line">    <span class="string">"i"</span>:txt,</div><div class="line">    <span class="string">"doctype"</span>:<span class="string">"json"</span>,</div><div class="line">    <span class="string">"xmlVersion"</span>:<span class="string">"1.8"</span>,</div><div class="line">    <span class="string">"keyfrom"</span>:<span class="string">"fanyi.web"</span>,</div><div class="line">    <span class="string">"ue"</span>:<span class="string">"UTF-8"</span>,</div><div class="line">    <span class="string">"action"</span>:<span class="string">"FY_BY_ENTER"</span>,</div><div class="line">    <span class="string">"typoResult"</span>:<span class="string">"true"</span></div><div class="line">&#125;</div><div class="line">data = urllib.urlencode(formdata)</div><div class="line">request = urllib2.Request(url, data=data, headers=headers)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line">html = eval(response.read())</div><div class="line"><span class="keyword">print</span> html[<span class="string">'translateResult'</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="string">'tgt'</span>]</div></pre></td></tr></table></figure></p>
<p>发送POST请求时，一些headers属性：</p>
<ul>
<li><code>Content-Length:144</code>：发送表单数据的长度为144，也就是144个字符</li>
<li><code>Content-Type:application/x-www-form-urlencoded</code>：表示浏览器提交Web表单时使用，表单数据会按照name1=value1&amp;name2=value2键值对进行编码</li>
<li><code>X-Requested-With:XMLHttpRequest</code>：表示AJAX异步请求</li>
</ul>
<h3 id="处理HTTPS请求-SLL证书验证"><a href="#处理HTTPS请求-SLL证书验证" class="headerlink" title="处理HTTPS请求 SLL证书验证"></a>处理HTTPS请求 SLL证书验证</h3><p>如果一个网站的SSL证书不是经过CA认证的，则会报错<br>12306URL：<code>https://www.12306.cn/mormhweb</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">url = <span class="string">'https://www.12306.cn/mormhweb'</span></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'</span>&#125;</div><div class="line">request = urllib2.Request(url, headers = headers)</div><div class="line">response = urllib2.urlopen(request)</div><div class="line"><span class="keyword">print</span> response.read()</div></pre></td></tr></table></figure></p>
<p>运行报错<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">urllib2.URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)&gt;</div></pre></td></tr></table></figure></p>
<p>需要单独处理SSL证书<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> ssl</div><div class="line"></div><div class="line">context = ssl._create_unverified_context()</div><div class="line">url = <span class="string">'https://www.12306.cn/mormhweb'</span></div><div class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'urllib2.URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)&gt;'</span>&#125;</div><div class="line">request = urllib2.Request(url, headers=headers)</div><div class="line">response = urllib2.urlopen(request,context=context)</div><div class="line"><span class="keyword">print</span> response.read()</div></pre></td></tr></table></figure></p>
<h2 id="urllib2-Handler处理器和自定义Opener"><a href="#urllib2-Handler处理器和自定义Opener" class="headerlink" title="urllib2:Handler处理器和自定义Opener"></a>urllib2:Handler处理器和自定义Opener</h2><ul>
<li><code>urlopen</code>是一种特殊的opener</li>
<li>基本的urlopen()不支持代理、cookie等HTTP/HTTPS高级功能，如果要支持：<ol>
<li>使用<code>Handler处理器</code>来创建特定功能的处理器对象</li>
<li>通过<code>urllib2.build_opener()</code>方法使用这些处理器，创建自定义opener对象</li>
<li>使用自定义opener对象，调用open()方法发送请求</li>
</ol>
</li>
<li>如果程序里所有的请求都使用自定义的opener，可使用<code>urllib2.install.opener()</code>将自定义的opener对象定义为全局opener，表示之后凡是调用urlopen，都将使用这个opener</li>
</ul>
<h3 id="简单自定义opener"><a href="#简单自定义opener" class="headerlink" title="简单自定义opener()"></a>简单自定义opener()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line">url = <span class="string">'http://www.baidu.com'</span></div><div class="line">http_handler = urllib2.HTTPHandler()</div><div class="line"><span class="comment"># https_handler = urllib2.HTTPSHandler()</span></div><div class="line">opener = urllib2.build_opener(http_handler)</div><div class="line">request = urllib2.Request(opener)</div><div class="line">response = opener.open(request)</div><div class="line"><span class="keyword">print</span> response.read()</div></pre></td></tr></table></figure>
<p>开启DEBUG模式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">http_handler = urllib2.HTTPHandler(debuglevel=<span class="number">1</span>)</div><div class="line">https_handler = urllib2.HTTPSHandler(debuglevel=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<h1 id="非架构化数据与结构化数据提取"><a href="#非架构化数据与结构化数据提取" class="headerlink" title="非架构化数据与结构化数据提取"></a>非架构化数据与结构化数据提取</h1><ul>
<li>非结构化数据：现有数据，再有结构<ul>
<li>文本、电话号码、邮箱<ul>
<li>正则</li>
</ul>
</li>
<li>HTML 文件<ul>
<li>正则</li>
<li>XPath</li>
<li>CSS选择器</li>
</ul>
</li>
</ul>
</li>
<li>结构化数据：现有结构，再有数据<ul>
<li>JSON文件<ul>
<li>JSON Path</li>
<li>转化成Python类型进行操作（json类）</li>
</ul>
</li>
<li>XML文件<ul>
<li>转化成Python</li>
<li>XPath</li>
<li>CSS选择器</li>
<li>正则表达式<h2 id="正则表达式re模块"><a href="#正则表达式re模块" class="headerlink" title="正则表达式re模块"></a>正则表达式re模块</h2><blockquote>
<p>正则通常用来检索、替换那些符合规则的文本</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>常用正则：</p>
<ol>
<li>字符<ul>
<li><code>.</code>：匹配除’\n’外<strong>任意字符</strong></li>
<li><code>\</code>：转义字符，改变原有意思</li>
</ul>
</li>
<li>预定义字符集<ul>
<li><code>\d</code>：数字[0-9]</li>
<li><code>\D</code>：非数字[^\d]</li>
<li><code>\s</code>：空白字符[&lt;空格&gt;\t\r\n\f\v]</li>
<li><code>\S</code>：非空白字符[^\s]</li>
<li><code>\w</code>：单词字符[A-Za-z0-9]</li>
<li><code>\W</code>：[^\w]</li>
</ul>
</li>
<li>数量词<ul>
<li><code>*</code>：0或多</li>
<li><code>+</code>：1或多</li>
<li><code>?</code>：0或1</li>
<li><code>{m}</code>：m次</li>
<li><code>{m,n}</code>：m到n次</li>
<li><code>*?  +?  ??  {m,n}?</code>：编程非贪婪模式</li>
</ul>
</li>
<li>边界匹配<ul>
<li><code>^</code>：匹配字符串开头</li>
<li><code>$</code>：匹配字符串结尾</li>
</ul>
</li>
</ol>
<h3 id="re模块步骤"><a href="#re模块步骤" class="headerlink" title="re模块步骤"></a>re模块步骤</h3><ol>
<li>使用<code>compile()</code>函数将正则表达式的字符串形成编译为一个<code>pattern</code>对象</li>
<li>使用<code>pattern</code>对象提供的一系列方法对文本进行匹配查询，获得匹配结果，一个Match对象</li>
<li>最后使用Match对象提供的属性和方法获得信息，根据需要进行其他的操作</li>
</ol>
<h3 id="compile函数"><a href="#compile函数" class="headerlink" title="compile函数"></a>compile函数</h3><p><code>compile</code>函数用于编译正则表达式，生成一个<code>Pattern</code>对象，使用方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">imoprt re</div><div class="line"><span class="comment"># 将正则表达式编译成 Pattern 对象</span></div><div class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</div></pre></td></tr></table></figure></p>
<p>使用pattern对象的方法对文本进行匹配查询</p>
<ul>
<li><code>match方法</code>：从起始位置开始查找，一次匹配</li>
<li><code>search方法</code>：从任意位置开始查找，一次匹配</li>
<li><code>findall方法</code>：全部匹配，返回列表</li>
<li><code>finditer方法</code>：全部匹配，返回迭代器</li>
<li><code>split方法</code>：分割字符串，返回列表</li>
<li><code>sub方法</code>：替换</li>
</ul>
<blockquote>
<p>ipython交互模式中记录所有命令到一个文件夹<code>%hist -f search.py</code></p>
</blockquote>
<h3 id="match方法"><a href="#match方法" class="headerlink" title="match方法"></a>match方法</h3><blockquote>
<p>用于查找字符串的头部，只匹配一次，只要找到了一个匹配结果就返回<code>match(string[,pos[,endpos]])</code></p>
<ul>
<li><code>string</code>：待匹配的字符串</li>
<li><code>pos</code>：开始位置</li>
<li><code>endpos</code>：结束位置</li>
</ul>
</blockquote>
<p><strong>match示例</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure></p>
<h3 id="匹配中文"><a href="#匹配中文" class="headerlink" title="匹配中文"></a>匹配中文</h3><p>保证中文编码为<code>unicode</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure></p>
<p>爬取段子代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Duanzi</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.baseURL = <span class="string">"http://www.neihan8.com/article/list_5_"</span></div><div class="line">        self.headers = &#123;<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36"</span>&#125;</div><div class="line">        self.page = <span class="number">1</span></div><div class="line">        self.switch = <span class="keyword">True</span></div><div class="line">        self.pattern_page = re.compile(<span class="string">r'&lt;div class="f18 mb20"&gt;(.*?)&lt;/div&gt;'</span>,re.S)</div><div class="line">        self.pattern_content = re.compile(<span class="string">r"&amp;(.*?);|&lt;(.*?)&gt;|\s"</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">            发送请求,返回提取后的段子的列表</div><div class="line">        '''</div><div class="line">        <span class="comment"># 构建完整的url,self.page是自增的</span></div><div class="line">        url = self.baseURL + str(self.page) + <span class="string">".html"</span></div><div class="line">        <span class="comment"># 发送请求,同时获取响应的HTML文本内容</span></div><div class="line">        html = requests.get(url, headers = self.headers).content</div><div class="line">        <span class="comment"># 将HTML转码:从GBK编码转换为UTF-8编码</span></div><div class="line">        html = html.decode(<span class="string">"gbk"</span>).encode(<span class="string">"utf-8"</span>)</div><div class="line">        <span class="comment"># 通过正则表达式匹配HTML内容,返回所有的段子列表</span></div><div class="line">        content_list = self.pattern_page.findall(html)</div><div class="line">        <span class="comment"># 返回段子列表给startWork</span></div><div class="line">        <span class="keyword">return</span> content_list</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">writePage</span><span class="params">(self,content_list)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">            将每条段子处理,去除无用字符,并写入到本地磁盘文件里</div><div class="line">        '''</div><div class="line">        <span class="comment"># 迭代获取每一条段子</span></div><div class="line">        <span class="keyword">with</span> open(<span class="string">"duanzi.txt"</span>,<span class="string">"a"</span>) <span class="keyword">as</span> f:</div><div class="line">            <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</div><div class="line">                <span class="comment"># 通过正则规则去除无用的实体字符</span></div><div class="line">                content = self.pattern_content.sub(<span class="string">""</span>,content)</div><div class="line">                <span class="comment"># 追加写入到磁盘文件</span></div><div class="line">                f.write(content)</div><div class="line">                f.write(<span class="string">"\n-------------\n"</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startWork</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="comment"># self.switch 默认是True</span></div><div class="line">        <span class="keyword">while</span> self.switch:</div><div class="line">            <span class="comment"># 如果用户输入Q,则退出循环,同时self.switch=False,循环结束</span></div><div class="line">            command = raw_input(<span class="string">"按回车键继续(按Q退出)"</span>)</div><div class="line">            <span class="keyword">if</span> command == <span class="string">"Q"</span>.lower():</div><div class="line">                self.switch = <span class="keyword">False</span></div><div class="line">                self.page = <span class="number">1</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="comment"># 获取loadPage()返回的段子列表</span></div><div class="line">                content_list = self.loadPage()</div><div class="line">                <span class="comment"># 调用writePage()写入磁盘文件</span></div><div class="line">                self.writePage(content_list)</div><div class="line">                <span class="comment"># 页数自增</span></div><div class="line">                self.page += <span class="number">1</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"抓取完毕"</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    duanzi = Duanzi()</div><div class="line">    duanzi.startWork()</div><div class="line">    <span class="comment"># print duanzi.startWork()</span></div></pre></td></tr></table></figure></p>
<p><strong>xpath</strong>默认下标从<code>1</code>开始</p>
<h2 id="XPath"><a href="#XPath" class="headerlink" title="XPath"></a>XPath</h2><p>最常用的路径表达式</p>
<ul>
<li><code>nodename</code>：选取此节点的所有子节点</li>
<li><code>/</code>：从跟节点选取</li>
<li><code>//</code>：从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置</li>
<li><code>.</code>：选取当前节点</li>
<li><code>..</code>：选取当前节点的父节点</li>
<li><code>@</code>：选取属性</li>
</ul>
<p>常用表达式示例</p>
<ul>
<li><code>bookstore</code>：选取bookstore元素的所有子节点</li>
<li><code>/bookstore</code>：选取根元素bookstore。注释：如果路径起始于正斜杠(/)，则此路径始终代表到某元素的<strong>绝对路径</strong></li>
<li><code>bookstore/book</code>：选取属性bookstore的子元素的所有book元素</li>
<li><code>//book</code>：选取所有book子元素，而不管它们在文档中的位置</li>
<li><code>bookstore//book</code>：选择属于bookstore元素的后代的所有book元素，而不管它们位于bookstore之下的什么位置</li>
<li><code>//@lang</code>：选取名为lang的所有属性</li>
</ul>
<h3 id="谓语"><a href="#谓语" class="headerlink" title="谓语"></a>谓语</h3><blockquote>
<p>用来查找某个<strong>特定的节点</strong>或包含某个<strong>指定值的节点</strong>，被嵌套在方括号中</p>
</blockquote>
<p>常用表达式和结果</p>
<ul>
<li><code>/bookstore/book[1]</code>：选取属于bookstore子元素的第一个book元素</li>
<li><code>/bookstore/book[last()]</code>：选取属于bookstore子元素的最后一个book元素</li>
<li><code>/bookstore/book[last()-1]</code>：选取属于bookstore子元素的倒数第二个book元素</li>
<li><code>/bookstore/book[position()&lt;3]</code>：选取最前面的两个属于bookstore元素的子元素的book元素</li>
<li><code>//title[@lang]</code>：选取所有拥有名为lang的属性的title元素</li>
<li><code>//title[@lang=&#39;eng&#39;]</code>：选取所有title属性，且这些元素拥有值为eng的lang属性</li>
<li><code>/bookstore/book[price&gt;35.00]</code>：选取bookstore元素的所有book元素，且其中的price元素的值必须大于35.00</li>
<li><code>/bookstroe/book[price&gt;35.00]/title</code>：选取bookstore元素中的book元素的所有title元素，且其中的price元素的值必须大于35.00</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/05/29/工具_git笔记2/" rel="next" title="Git笔记2">
                <i class="fa fa-chevron-left"></i> Git笔记2
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/06/13/工具_FishShell/" rel="prev" title="Fish shell">
                Fish shell <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="金成" />
          <p class="site-author-name" itemprop="name">金成</p>
           
              <p class="site-description motion-element" itemprop="description">IT学习分享博客</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/">
                <span class="site-state-item-count">67</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#爬虫原理与数据抓取"><span class="nav-number">1.</span> <span class="nav-text">爬虫原理与数据抓取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#通用爬虫和聚焦爬虫"><span class="nav-number">1.1.</span> <span class="nav-text">通用爬虫和聚焦爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#通用爬虫"><span class="nav-number">1.1.1.</span> <span class="nav-text">通用爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#第一步：抓取网页"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">第一步：抓取网页</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#第二步：数据存储"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">第二步：数据存储</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#第三步：预处理"><span class="nav-number">1.1.1.3.</span> <span class="nav-text">第三步：预处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#第四步：提供检索服务，网站排名"><span class="nav-number">1.1.1.4.</span> <span class="nav-text">第四步：提供检索服务，网站排名</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HTTP和HTTPS"><span class="nav-number">1.2.</span> <span class="nav-text">HTTP和HTTPS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HTTP工作原理"><span class="nav-number">1.2.1.</span> <span class="nav-text">HTTP工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#浏览器发送HTTP请求的过程"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">浏览器发送HTTP请求的过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#URL"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">URL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#客户端HTTP请求"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">客户端HTTP请求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#请求方法"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">请求方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#常用的请求报头"><span class="nav-number">1.2.1.5.</span> <span class="nav-text">常用的请求报头</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#服务端HTTP响应"><span class="nav-number">1.2.1.6.</span> <span class="nav-text">服务端HTTP响应</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cookie和Session"><span class="nav-number">1.2.2.</span> <span class="nav-text">Cookie和Session</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urllib2库的基本使用"><span class="nav-number">1.3.</span> <span class="nav-text">urllib2库的基本使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#urlopen"><span class="nav-number">1.3.1.</span> <span class="nav-text">urlopen</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Request"><span class="nav-number">1.3.2.</span> <span class="nav-text">Request</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#User-Agent"><span class="nav-number">1.3.3.</span> <span class="nav-text">User-Agent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#添加更多的Header信息"><span class="nav-number">1.3.4.</span> <span class="nav-text">添加更多的Header信息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urllib2：GET和POST方法"><span class="nav-number">1.4.</span> <span class="nav-text">urllib2：GET和POST方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#URL编码转码：urllib的urlencode"><span class="nav-number">1.4.1.</span> <span class="nav-text">URL编码转码：urllib的urlencode()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Get方式"><span class="nav-number">1.4.2.</span> <span class="nav-text">Get方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#百度贴吧小爬虫"><span class="nav-number">1.4.3.</span> <span class="nav-text">百度贴吧小爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取AJAX加载的内容"><span class="nav-number">1.4.4.</span> <span class="nav-text">获取AJAX加载的内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#POST方式"><span class="nav-number">1.4.5.</span> <span class="nav-text">POST方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#处理HTTPS请求-SLL证书验证"><span class="nav-number">1.4.6.</span> <span class="nav-text">处理HTTPS请求 SLL证书验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urllib2-Handler处理器和自定义Opener"><span class="nav-number">1.5.</span> <span class="nav-text">urllib2:Handler处理器和自定义Opener</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简单自定义opener"><span class="nav-number">1.5.1.</span> <span class="nav-text">简单自定义opener()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#非架构化数据与结构化数据提取"><span class="nav-number">2.</span> <span class="nav-text">非架构化数据与结构化数据提取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#正则表达式re模块"><span class="nav-number">2.1.</span> <span class="nav-text">正则表达式re模块</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#re模块步骤"><span class="nav-number">2.1.1.</span> <span class="nav-text">re模块步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#compile函数"><span class="nav-number">2.1.2.</span> <span class="nav-text">compile函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#match方法"><span class="nav-number">2.1.3.</span> <span class="nav-text">match方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#匹配中文"><span class="nav-number">2.1.4.</span> <span class="nav-text">匹配中文</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XPath"><span class="nav-number">2.2.</span> <span class="nav-text">XPath</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#谓语"><span class="nav-number">2.2.1.</span> <span class="nav-text">谓语</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-coffee"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">金成</span>
</div>



        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

</body>
</html>
